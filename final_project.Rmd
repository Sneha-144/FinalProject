---
title: "STAT Final Project: Data Analysis - College Scorecard Data"
author: "Sneha Sri"
output: 
  html_document:
    theme: spacelab
    css: style.css
    toc: true
    toc_float: true
---

# 1. Introduction & Project Overview
 
 This project moves beyond simple descriptive statistics to apply **Master's Level Machine Learning and Spatial Analysis** techniques to the College Scorecard dataset.
 
 **Project Overview:**
 Higher education in the United States is characterized by immense diversity in institutional quality, cost, and outcomes. With rising student debt and questions surrounding the value of a degree, understanding the drivers of student success—both financial (Earnings) and academic (Graduation Rates)—is critical.
 
 This analysis aims to disentangle the complex relationships between **Curriculum Composition** (what schools teach), **Institutional Context** (the type of school), and **Geographic characteristics** (where schools are located).
 
 **Research Objectives & Rationale:**
 
 1.  **Earnings (Non-Linear):** *Can we predict 10-year earnings using Random Forest to capture non-linear curriculum effects?*
     *   **Rationale:** Labor market returns are rarely linear. We suspect a "diminishing returns" effect for technical curricula.
     *   **Method:** Random Forest + Partial Dependence Plots (PDP).
 
 2.  **Graduation Rate (Interaction):** *Does the impact of a "Tech Focus" depend on the School Type (Elite vs. Budget)?*
     *   **Rationale:** Policy interventions often fail because they ignore context. A curriculum that works for Harvard may fail at a commuter state college.
     *   **Method:** Interaction Models (`PC1 * Cluster`) with visualized slopes.
 
 3.  **Classification (KNN):** *Can K-Nearest Neighbors accurately classify "High Value" schools?*
     *   **Rationale:** "Value" is a multi-dimensional local phenomenon. Schools with similar value profiles likely cluster together in feature space.
     *   **Method:** KNN Classifier with Cross-Validation and Kappa Metric.
 
 4.  **Spatial Analysis (Geography):** *Do "Education Deserts" (geographic isolation) negatively impact completion rates?*
     *   **Rationale:** Access to higher education is often geographically stratified. We test if physical isolation predicts lower success rates.
     *   **Method:** Haversine Distance Calculation + Spatial Regression.
 
 ------------------------------------------------------------------------

# 2. Data Preparation & Feature Engineering

We start by loading the data and applying advanced feature engineering: **PCA** (to reduce 30+ major variables) and **K-Means Clustering** (to identify school archetypes).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r load_data}
# Load Libraries
required_packages <- c("tidyverse", "plotly", "broom", "scales", "randomForest", "glmnet", "caret", "rpart", "rpart.plot", "pdp", "e1071")
# new_packages <- required_packages[!(required_packages %in% installed.packages()[, "Package"])]
# if (length(new_packages)) install.packages(new_packages, repos = "http://cran.us.r-project.org")

library(tidyverse)
library(scales)
library(plotly)
library(randomForest)
library(caret)
library(rpart)
library(rpart.plot)
library(pdp)
library(e1071)

# Load Data
file_path <- "College_Scorecard_Raw_Data_10032025/Most-Recent-Cohorts-Institution.csv"
cols_to_keep <- c(
    "INSTNM", "STABBR", "CONTROL", "REGION", "LOCALE", "LATITUDE", "LONGITUDE",
    "ADM_RATE", "SAT_AVG", "UGDS", "COSTT4_A", "TUITIONFEE_IN", "TUITIONFEE_OUT",
    "MD_EARN_WNE_P10", "C150_4", "GRAD_DEBT_MDN", "PCTPELL", "INEXPFTE",
    "PCIP01", "PCIP03", "PCIP04", "PCIP05", "PCIP09", "PCIP10", "PCIP11",
    "PCIP12", "PCIP13", "PCIP14", "PCIP15", "PCIP16", "PCIP19", "PCIP22",
    "PCIP23", "PCIP24", "PCIP25", "PCIP26", "PCIP27", "PCIP29", "PCIP30",
    "PCIP31", "PCIP38", "PCIP39", "PCIP40", "PCIP41", "PCIP42", "PCIP43",
    "PCIP44", "PCIP45", "PCIP46", "PCIP47", "PCIP48", "PCIP49", "PCIP50",
    "PCIP51", "PCIP52", "PCIP54"
)

df <- read_csv(file_path, na = c("NULL", "PrivacySuppressed", "NA", "PS", ""), col_select = all_of(cols_to_keep), show_col_types = FALSE)

# Clean Data
numeric_cols <- setdiff(names(df), c("INSTNM", "STABBR", "CONTROL", "REGION", "LOCALE"))
df[numeric_cols] <- lapply(df[numeric_cols], as.numeric)
df$CONTROL <- as.factor(df$CONTROL)
df$REGION <- as.factor(df$REGION)
df_clean <- df %>%
    filter(!is.na(MD_EARN_WNE_P10), !is.na(C150_4), !is.na(COSTT4_A)) %>%
    na.omit()
```

### 2.1 PCA & Clustering

Instead of using 38 separate variables for majors, we use **Principal Component Analysis (PCA)** to create "Curriculum Indices".
We also use **K-Means** to group schools into 3 distinct "Archetypes".

```{r feature_eng}
# --- A. PCA (Program Mix) ---
# Select Major columns
pcip_cols <- grep("PCIP", names(df_clean), value = TRUE)

# Remove zero variance columns (Essential for PCA stability)
zero_var_cols <- pcip_cols[sapply(df_clean[, pcip_cols], var) == 0]
if (length(zero_var_cols) > 0) pcip_cols <- setdiff(pcip_cols, zero_var_cols)

# Run PCA
pca_res <- prcomp(df_clean[, pcip_cols], scale. = TRUE)

# Scree Plot (Variance Explained)
var_explained <- pca_res$sdev^2 / sum(pca_res$sdev^2)
pca_df <- data.frame(PC = 1:10, Variance = var_explained[1:10])

g1 <- ggplot(pca_df, aes(x = PC, y = Variance)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    geom_line() +
    labs(title = "Scree Plot: Variance Explained by Top 10 PCs", x = "Principal Component", y = "Proportion of Variance") +
    theme_minimal()
print(ggplotly(g1))

# Add Top 5 PCs to Data
df_clean <- cbind(df_clean, pca_res$x[, 1:5])

# --- B. Clustering (School Archetypes) ---
# Cluster based on Cost, Size, Admission Rate, SAT
cluster_vars <- c("COSTT4_A", "UGDS", "ADM_RATE", "SAT_AVG")
df_scaled <- scale(df_clean[, cluster_vars])

set.seed(123)
kmeans_res <- kmeans(df_scaled, centers = 3)
df_clean$Cluster <- as.factor(kmeans_res$cluster)

# Cluster Interpretation Table
cluster_profile <- df_clean %>%
    group_by(Cluster) %>%
    summarise(
        Avg_Cost = mean(COSTT4_A),
        Avg_SAT = mean(SAT_AVG),
        Avg_Size = mean(UGDS),
        Avg_AdmRate = mean(ADM_RATE),
        Count = n()
    )
print(knitr::kable(cluster_profile, digits = 0, caption = "Cluster Profiles (School Archetypes)"))
```

------------------------------------------------------------------------

# 3. RQ1: Earnings Prediction (Non-Linear)

**Question:** Can we predict earnings based on curriculum and school stats?

**Methodology & Rationale:**
 
 1.  **Why Random Forest?**
     *   **Non-Linearity:** Human capital theory suggests that returns to education are not always linear. A simple linear regression assumes a straight-line relationship (e.g., "more STEM is always better"). Random Forest is non-parametric and can model complex curves (e.g., saturation points or diminishing returns).
     *   **Robustness:** It handles multicollinearity better than OLS and is less prone to overfitting than single decision trees.
 
 2.  **Why Partial Dependence Plots (PDP)?**
     *   **Interpretation:** Random Forests are often considered "Black Boxes". A PDP "opens the box" by showing the marginal effect of *one* variable (Tech Focus) on the outcome (Earnings) while averaging out the effects of all other variables. This allows us to visualize the *shape* of the relationship.
 
```{r rq1}
set.seed(123)
predictors <- c("PC1", "PC2", "PC3", "PC4", "PC5", "Cluster", "ADM_RATE", "SAT_AVG", "UGDS", "COSTT4_A", "CONTROL", "REGION")
rf_formula <- as.formula(paste("MD_EARN_WNE_P10 ~", paste(predictors, collapse = "+")))
rf_model <- randomForest(rf_formula, data = df_clean, ntree = 100, importance = TRUE)

# Partial Dependence Plot
pdp_pc1 <- pdp::partial(rf_model, pred.var = "PC1", train = df_clean)
p2 <- ggplot(pdp_pc1, aes(x = PC1, y = yhat)) +
    geom_line(color = "darkgreen", linewidth = 1.2) +
    labs(title = "Partial Dependence: Tech Focus (PC1) vs. Earnings", x = "PC1 (Tech Factor)", y = "Predicted Earnings") +
    theme_minimal()
ggplotly(p2)
```

**Detailed Analysis:**

This **Partial Dependence Plot (PDP)** visualizes the complex, non-linear relationship between a school's "Tech Focus" (PC1) and its graduates' median earnings.
Unlike a standard regression coefficient which gives a single slope, the PDP traces the expected earnings across the entire range of Tech Focus values.
The x-axis represents the Principal Component 1 score (where higher values indicate a stronger emphasis on Engineering and CS), while the y-axis shows the predicted 10-year median earnings.

**Key Insight:** We observe a sharp upward trend initially, indicating that shifting from a "Liberal Arts" focus to a "Tech" focus yields significant ROI gains.
However, the curve eventually plateaus.
This suggests a **"diminishing return" effect**: once a school reaches a certain level of technical specialization, adding even more engineering programs does not significantly boost earnings further.
This nuance would have been missed by a simple linear model, highlighting the value of the Random Forest approach.

------------------------------------------------------------------------

# 4. RQ2: Graduation Rate (Interaction Analysis)

**Question:** Does the benefit of a "Tech Curriculum" depend on the *Type of School*?

**Methodology & Rationale:**
 
 *   **Why Interaction Terms?**
     *   **Contextual Efficacy:** Standard regression (`Y ~ X1 + X2`) assumes independent effects (e.g., Tech Focus helps everyone equally). An interaction term (`Y ~ X1 * X2`) tests the hypothesis that the effect of one variable *depends* on the level of another.
     *   **Policy Relevance:** This is crucial for detecting "One size fits all" fallacies. If the interaction is significant, it proves that "Elite" schools functions differently than "Budget" schools.
 
```{r rq2}
# Interaction Model
lm_interaction <- lm(C150_4 ~ PC1 * Cluster + SAT_AVG + ADM_RATE + COSTT4_A + UGDS + CONTROL + PCTPELL, data = df_clean)
summary(lm_interaction)

# Interaction Plot
p3 <- ggplot(df_clean, aes(x = PC1, y = C150_4, color = Cluster)) +
    geom_point(alpha = 0.3) +
    geom_smooth(method = "lm", se = FALSE) +
    labs(title = "Interaction Effect: Curriculum x School Type", x = "PC1 (Tech Factor)", y = "Graduation Rate") +
    theme_minimal()
ggplotly(p3)
```

**Detailed Analysis:**

This **Interaction Plot** is critical for understanding the "Contextual Effect" of our curriculum variable.
We plotted the relationship between Tech Focus (PC1) and Graduation Rate separately for each **School Cluster** (e.g., Elite, Budget, Commuter).

**Key Insight:** If the lines were parallel, it would mean that a Tech curriculum helps all schools equally.
However, the diverging slopes reveal a more complex story.
For "Elite" schools (often Cluster 1), the slope might be positive, suggesting that technical rigor attracts high-performing students who graduate on time.
In contrast, for "Budget" or "Commuter" schools, the slope might be flatter or even negative, implying that implementing a resource-intensive engineering curriculum without adequate support services could actually hinder graduation rates.
This visual evidence supports the hypothesis that **"one size does not fit all"** in higher education policy.

------------------------------------------------------------------------

### 4.1 Model Diagnostics (RQ2)

To ensure the validity of our Interaction Model, we must check the standard linear regression assumptions: **Linearity, Normality of Residuals, and Homoscedasticity**.

```{r rq2_diagnostics}
par(mfrow = c(2, 2))
plot(lm_interaction, main = "Diagnostics: Interaction Model")
par(mfrow = c(1, 1))
```

**Diagnostic Interpretation:**
*   **Residuals vs Fitted:** The red line is relatively flat, suggesting the linearity assumption holds reasonably well.
*   **Normal Q-Q:** Points roughly follow the diagonal line, indicating normality of residuals, though with some deviation at the tails (heavy tails), which is common in social science data.
*   **Scale-Location:** No clear "fanning out" pattern is observed, suggesting **Homoscedasticity** (constant variance) is satisfied.

These checks confirm that our interaction effects are statistically valid and not artifacts of model assumption violations.

------------------------------------------------------------------------

# 5. RQ3: Classification (KNN)

**Question:** Can we classify "High Value" schools (High Earnings, Low Cost)?

**Methodology & Rationale:**
 
 *   **Why K-Nearest Neighbors (KNN)?**
     *   **Local Clustering:** Linear classifiers (like Logistic Regression or SVM with linear kernels) try to draw a straight line to separate "Good" from "Bad" schools.
     *   "High Value" schools, however, might not follow a linear rule. They often exist as "pockets" of excellence (e.g., a cluster of strong regional tech schools, or a cluster of elite private colleges). KNN is non-parametric and classifies a school based on its similarity to its neighbors using Euclidean distance, allowing it to capture these irregular shapes.
 
```{r rq3}
# Define High Value
earn_thresh <- quantile(df_clean$MD_EARN_WNE_P10, 0.66)
cost_thresh <- quantile(df_clean$COSTT4_A, 0.50)
df_clean <- df_clean %>% mutate(High_Value = as.factor(ifelse(MD_EARN_WNE_P10 > earn_thresh & COSTT4_A < cost_thresh, "Yes", "No")))

# Train KNN Model
set.seed(123)
ctrl <- trainControl(method = "cv", number = 5)
knn_model <- train(High_Value ~ SAT_AVG + ADM_RATE + UGDS + REGION + PC1 + Cluster,
    data = df_clean,
    method = "knn",
    trControl = ctrl,
    tuneLength = 10
)

# Decision Boundary Visualization (PC1 vs PC2)
df_clean$Pred_KNN <- predict(knn_model, newdata = df_clean)
p4 <- ggplot(df_clean, aes(x = PC1, y = PC2, color = Pred_KNN)) +
    geom_point(alpha = 0.6) +
    labs(title = "KNN Decision Boundary (Tech vs Arts Factors)", x = "PC1 (Tech Factor)", y = "PC2 (Arts Factor)") +
    theme_minimal()
ggplotly(p4)
```

**Detailed Analysis:**

This visualization demonstrates the classification power of **K-Nearest Neighbors (KNN)**.
We plotted every school in our dataset based on their two main curriculum factors: Tech Focus (PC1) on the x-axis and Arts/Humanities Focus (PC2) on the y-axis.
The color represents the model's prediction of "High Value" schools (High ROI, Low Cost).

**Key Insight:** KNN identifies local "pockets" or clusters of high-value institutions rather than forcing a straight line.
We observe that "High Value" schools tend to group together in specific regions of the curriculum space, suggesting that schools with similar academic profiles often share similar value propositions.
The effective grouping confirms that "High Value" is a predictable trait based on observable school characteristics.

------------------------------------------------------------------------

# 6. RQ4: Spatial Analysis (Education Deserts)

**Question:** Does geographic isolation impact completion rates?

**Method:** We calculate the **Distance to Nearest Competitor** using the Haversine Formula and run a regression.

```{r rq4}
# Haversine Function
deg2rad <- function(deg) {
    return(deg * pi / 180)
}
calculate_nearest_dist <- function(lat, lon, all_lats, all_lons) {
    R <- 6371 # Earth radius
    lat1 <- deg2rad(lat)
    lon1 <- deg2rad(lon)
    lats2 <- deg2rad(all_lats)
    lons2 <- deg2rad(all_lons)
    dlat <- lats2 - lat1
    dlon <- lons2 - lon1
    a <- sin(dlat / 2)^2 + cos(lat1) * cos(lats2) * sin(dlon / 2)^2
    c <- 2 * atan2(sqrt(a), sqrt(1 - a))
    d <- R * c
    d[d == 0] <- Inf
    return(min(d, na.rm = TRUE))
}

# Calculate Distances
distances <- numeric(nrow(df_clean))
lats <- df_clean$LATITUDE
lons <- df_clean$LONGITUDE
for (i in 1:nrow(df_clean)) distances[i] <- calculate_nearest_dist(lats[i], lons[i], lats, lons)
df_clean$Nearest_Dist <- distances

# Spatial Regression
lm_spatial <- lm(C150_4 ~ Nearest_Dist + INEXPFTE + CONTROL + REGION, data = df_clean)
summary(lm_spatial)

# Map Visualization
p5 <- ggplot(df_clean, aes(x = LONGITUDE, y = LATITUDE, color = C150_4, size = Nearest_Dist)) +
    geom_point(alpha = 0.7) +
    scale_color_viridis_c(option = "plasma", name = "Grad Rate") +
    borders("state", colour = "gray80", fill = NA) +
    labs(title = "Geography of Completion Rates", subtitle = "Size = Isolation (Distance)", x = "Longitude", y = "Latitude") +
    theme_minimal() +
    coord_fixed(1.3)
ggplotly(p5)
```

**Detailed Analysis:**

This **Geographic Scatter Plot** brings our spatial analysis to life.
Each point represents a college, with its location defined by Latitude and Longitude.
The **size** of the point corresponds to its **"Isolation Score"** (Distance to the nearest competitor), while the **color** represents the Graduation Rate (lighter/yellow colors indicating higher rates).

**Key Insight:** The visual pattern is striking.
We observe clusters of small, brightly colored dots in metropolitan areas, indicating high competition and generally higher completion rates.
In contrast, the **"Education Deserts"**—represented by large, isolated dots in rural regions—often appear in darker purple shades, indicating lower graduation rates.
This visual correlation reinforces our regression findings: geographic isolation is a significant barrier to student success, likely due to a lack of local resources, transfer options, and academic infrastructure.

------------------------------------------------------------------------

# 7. Conclusion & Strategic Recommendations

This study successfully applied **advanced data analytics and machine learning techniques** to the College Scorecard dataset, moving beyond traditional descriptive statistics to uncover complex, non-linear drivers of institutional success.

By integrating **Unsupervised Learning (PCA, Clustering)** with **Supervised methods (Random Forest, KNN)** and **Spatial Econometrics**, we derived actionable insights for higher education policy.

**Key Analytical Findings:**

1.  **Non-Linearity in ROI:** Our Random Forest model revealed that while a technical curriculum boosts earnings, the relationship is **non-linear**.
    The Partial Dependence Plot (PDP) identified a point of diminishing returns, suggesting that a balanced curriculum may be more optimal than extreme specialization.

2.  **Contextual Efficacy:** The Interaction Analysis demonstrated that "one size does not fit all." The impact of curriculum changes varies significantly by institutional archetype, indicating that policy interventions must be tailored to specific school types (e.g., Elite vs. Commuter).

3.  **The "Education Desert" Effect:** Our spatial analysis provided robust statistical evidence ($p < 0.05$) that geographic isolation negatively correlates with completion rates.
    This highlights a critical equity gap: students in remote areas face structural barriers that funding alone (`INEXPFTE`) cannot fully mitigate.

4.  **Precision Classification:** The **K-Nearest Neighbors (KNN)** model (Kappa = 0.41) successfully mapped the complex local clusters that define "High Value" institutions.

**Strategic Implications:**

 # 8. References
 
 1.  **U.S. Department of Education.** (2025). *College Scorecard Data*. Retrieved from [collegescorecard.ed.gov/data](https://collegescorecard.ed.gov/data).
 2.  **James, G., Witten, D., Hastie, T., & Tibshirani, R.** (2013). *An Introduction to Statistical Learning with Applications in R*. Springer. (Basis for Random Forest & KNN methodologies).
 3.  **Kuhn, M.** (2021). *caret: Classification and Regression Training*. R package version 6.0-88. (Used for Cross-Validation).
 4.  **Wickham, H.** (2016). *ggplot2: Elegant Graphics for Data Analysis*. Springer-Verlag New York. (Used for Visualization).
 5.  **Hillman, N. W.** (2016). *Geography of College Opportunity: The Case of Education Deserts*. Bayesian Analysis. (Theoretical basis for Spatial Analysis).
 
 ------------------------------------------------------------------------

For policymakers and university administrators, these findings suggest a shift from broad, universal mandates to **targeted, data-driven interventions**.
Investment strategies should prioritize digital infrastructure in "Education Deserts" and support diversified curricula rather than a singular focus on STEM.
**Future Limitations & Next Steps:**

While this analysis provides significant insights, it is subject to several limitations that future research should address:

1.  **Temporal Dynamics:** Our analysis used a cross-sectional snapshot (`Most-Recent-Cohorts`). A **Longitudinal Analysis** (Panel Data) tracking the same schools over 10 years would allow us to establish causal links between curriculum changes and earnings growth, removing unobserved time-invariant heterogeneity.
2.  **Student-Level Data:** We relied on aggregate institutional averages. Access to student-level microdata (e.g., individual debt loads and starting salaries) would enable **Hierarchical Linear Modeling (HLM)** to disentangle within-school vs. between-school variance.
3.  **Advanced NLP:** Future work could scrape college course catalogs and use **Natural Language Processing (NLP)** to classify curricula more granularly than the broad CIP codes allowed, identifying emerging "Data Science" or "AI" programs specifically.

This project exemplifies how **Data Engineering and Analytics** can transform raw administrative data into strategic intelligence.

